{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Pandas\n",
    "\n",
    "Pandas is a very important Python Library for manipulating objects called DataFrames which are crucial in performing data science. In this section, we will go over the basics of Pandas but it is highly encouraged for you to read Chapter 3 of the [Python for Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Pandas\n",
    "Pandas is not a package found in base Python so it must be imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame Basics\n",
    "A dataframe is essentially a table. It has rows and columns and each column has a heading. Just as we work with large tables with Excel we want to work in a similar way with data in Python. The advantage of Pandas is that it can handle far larger table sizes than Excel, the data wrangling is more robust and it's much easier than Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame\n",
    "## From a Python Dictionary\n",
    "df = pd.DataFrame({'name': ['Bob', 'Lisa', 'Mike', 'Fatima', 'Zahra', 'Ali', 'Maryam', 'Maryam'],\n",
    "'Age': [23, 23, 25, 19, 42, '54', 107, 107],\n",
    "'Sex': ['M', 'F', 'M', 'F', 'F', 'M', 'F', 'F'],\n",
    "'Job': ['Designer', 'Marketing Manager', 'Product Manager', 'Software Engineer', 'Data Scientist', 'Machine Learning Engineer', np.NaN, np.NaN],\n",
    "'Hobbies': ['Waterskiing', 'Skydiving', 'Rock Climbing', 'Skateboarding', 'Baking', 'Improv Acting', 'Trolling', 'Trolling']})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview a Dataframe\n",
    "## Head: view first 5 rows\n",
    "df.head()\n",
    "#df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tail: view final 5 rows\n",
    "df.tail()\n",
    "#df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Show column names \n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Shape: Get rows and columns of a dataframe\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df)) ## Rows\n",
    "print(len(df.columns)) ## Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Show data types for each column in a dataframe\n",
    "df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Show data types for a particular column in a dataframe\n",
    "df['Sex'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Subsetting columns in a dataframe. We use the square brackets like we do with lists\n",
    "df['name']\n",
    "#df[['name', 'Hobbies']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset rows with iloc\n",
    "df.iloc[[3], :] # Gets 3rd row and all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[[3,4], :] # Gets rows 3 and 4 and all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:, [2]] # Gets all rows and only 2nd column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:, [3,4]] # Gets all rows and 3rd and 4th columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[[0,1], [3,4]] # Gets 0th and 1st rows and 3rd and 4th columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get unique values for a column\n",
    "df['Age'].unique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive Stats for a Dataframe\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can count values for the dataframe\n",
    "df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's more helpful to count unique occuring values by column\n",
    "print(df[['Age']].value_counts())\n",
    "print(df[['Sex']].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast column types: We can look at the Age column and realise it's a object/ string. It doesn't need to be, so we cast it to integer which is a more appropriate type\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do this, we use the astype() method\n",
    "\n",
    "df['Age'] = df['Age'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling\n",
    "\n",
    "Data Wrangling involves manipulating the data contained within the dataframe itself. There are 5 major operations involved in data wrangling and all of them are essential when performing any operations pertaining to data analysis.\n",
    "\n",
    "1. Filtering rows\n",
    "2. Mutating columns\n",
    "3. Sorting rows\n",
    "4. Renaming columns\n",
    "5. Grouping and Aggregating rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make a copy of the dataframe so our changes don't affect the original.\n",
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows\n",
    "## Single filters\n",
    "df_copy[df_copy.Job == 'Data Scientist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Multiple Filters\n",
    "df_copy[(df_copy.Sex == 'F') & (df_copy.Age > 24)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if values are within a range\n",
    "df_copy[df_copy.Job.isin(['Designer', 'Machine Learning Engineer'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return values NOT in a range\n",
    "df_copy[~df_copy.Hobbies.isin(['Trolling', 'Skydiving'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mutate columns\n",
    "## Make a new column from the existing columns\n",
    "df_copy['new_age'] = df_copy['Age'] - 2\n",
    "df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply a function to every row in a column\n",
    "df_copy['log_age'] = df_copy['Age'].apply(np.log)\n",
    "df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Can apply custom lambda functions to columns\n",
    "df_copy['full_hobbies'] = df_copy['Hobbies'].apply(lambda x: x + ' & Scuba Diving')\n",
    "df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can apply a function to a column and then replace that column\n",
    "df_copy['Sex'] = df_copy['Sex'].apply(lambda x: x.lower())\n",
    "df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort values\n",
    "df_copy.sort_values(by = ['Age'], ascending = [True])\n",
    "#df_copy.sort_values(by = ['Age'], ascending = [False])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Can also sort by alphabetical order if the values inside are strings\n",
    "df_copy.sort_values(by = ['Hobbies'], ascending = [True])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sorting by multiple columns. Sort by age and then by oldest first\n",
    "df_copy.sort_values(by = ['Sex', 'Age'], ascending = [True, False])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename Columns\n",
    "## Give a new columns list - We want to change name to Name\n",
    "df_copy.columns = ['Name', 'Age', 'Sex', 'Job', 'Hobbies', 'new_age', 'log_age', 'full_hobbies']\n",
    "df_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Change selected column names via a dictionary.\n",
    "df_copy = df_copy.rename(columns = {'new_age': 'Younger_Age', 'log_age': 'Log_Age'})\n",
    "df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping and Aggregating\n",
    "## What is the mean age by gender?\n",
    "df_copy.groupby(['Sex'], as_index=False).agg({'Age': 'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can aggregate with multiple functions\n",
    "df_copy.groupby(['Sex'], as_index=False).agg({'Age': ['mean', 'min', 'max']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add a new column for Salary and Ethnic Name\n",
    "df_copy['Salary'] = [72, 65, 67, 71, 70, 89, 23, 23]\n",
    "df_copy['Ethnic_Name'] = [\"n\", \"n\", \"n\", \"n\", \"y\", \"y\", \"y\", \"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.groupby(['Sex'], as_index=False).agg({'Salary': ['mean', 'median']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can group by multiple columns\n",
    "df_copy.groupby(['Sex', 'Ethnic_Name'], as_index=False).agg({'Salary': ['mean', 'median']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Making your own aggregation functions - These run much slower for large dataframes. \n",
    "## We make a function to compute the exponential values for an array and then compute the mean.\n",
    "def exp_mean(x):\n",
    "    y = np.exp(np.array(x))\n",
    "    return np.mean(y)\n",
    "\n",
    "#exp_mean([1,2,3,4])\n",
    "\n",
    "df_copy.groupby(['Sex'], as_index=False).agg({'Salary': exp_mean})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional Logic with Dataframes\n",
    "It is useful to perform if else logic on columns to extract data of interest and to mutate the dataframe more intelligently. For this we will need 2 numpy functions - `np.where` and `np.select`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary logic - Suppose we were creating a special club where the age of entry is 25 or over.\n",
    "# Let's see who in our dataset qualifies to be a member.\n",
    "df_copy['eligible_for_membership'] = np.where(df_copy.Age >= 25, True, False)\n",
    "df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More than 2 conditions. When we have complex if else logic we can use np.select\n",
    "# Suppose we wanted to flag which hobbies were considered adventurous in varying degrees\n",
    "df_copy['Adventurous'] = np.select([df_copy.Hobbies == 'Waterskiing'\n",
    ", df_copy.Hobbies == 'Skydiving'\n",
    ", df_copy.Hobbies == 'Rock Climbing'\n",
    ", df_copy.Hobbies == 'Skateboarding'\n",
    ", df_copy.Hobbies == 'Baking'\n",
    "]\n",
    ", ['very_adventurous'\n",
    ", 'extremely_adventurous'\n",
    ", 'adventurous'\n",
    ", 'adventurous'\n",
    ", 'not adventurous']\n",
    ", default = 'mildly_adventurous')\n",
    "\n",
    "df_copy[['Name', 'Hobbies', 'Adventurous']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Dataframes\n",
    "\n",
    "Many times we will have more than one dataframe to deal with at once and we may wish to combine the data in scattered dataframes in different ways. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Union Dataframes/ Stack them on top of each other\n",
    "df2 = pd.DataFrame({'name': ['James', 'Frankie'],\n",
    "'Age': [47, 48],\n",
    "'Sex': ['M', 'F'],\n",
    "'Job': ['Accountant', 'Chef'],\n",
    "'Hobbies': ['Travelling', 'Kickboxing']})\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.concat([df, df2], ignore_index=True)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add columns to a dataframe \n",
    "df_extra_cols = pd.DataFrame({'Country': ['USA', 'Japan', 'UK', 'UK', 'UK', 'Tanzania', 'Narnia', 'Narnia', 'Australia', 'Netherlands']})\n",
    "df4 = pd.concat([df3, df_extra_cols], axis = 1) # axis = 1 tells pandas that you're joining columns and not rows\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining Dataframes\n",
    "## One common key between dataframes - replaces Vlookup in Excel\n",
    "df_a = pd.DataFrame({'Country': ['USA', 'Japan', 'UK', 'Tanzania', 'Australia', 'Netherlands'],\n",
    "'National_Sport': ['Baseball', 'Sumo', 'Football', 'Football', 'Netball', 'Cycling']})\n",
    "\n",
    "df_a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4a = pd.merge(df4, df_a, on = ['Country'], how = 'left')\n",
    "df_4a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple Keys \n",
    "df_b = pd.DataFrame({'Country': ['USA', 'USA', 'Japan', 'Japan', 'UK', 'UK'],\n",
    "'Sex': ['M', 'F', 'M', 'F', 'M', 'F'],\n",
    "'Sexist_National_Sport': ['Baseball', 'Cheerleading', 'Sumo', 'Ballet', 'Football', 'Gymnastics']})\n",
    "\n",
    "df_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4b = pd.merge(df4, df_b, on = ['Country', 'Sex'], how = 'left')\n",
    "df_4b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with Null Values and Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Null values\n",
    "df['Job'].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all rows with a Null value in at least one column. Not an inplace operation.\n",
    "df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace Null value with a value\n",
    "df['Job_notnull']= df['Job'].fillna('Tik Tok Star')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrict dataframe to only Null rows\n",
    "df[pd.isnull(df.Job)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which rows are duplicated in a column. Will flag the duplicated values, not the first occurrence.\n",
    "df['Age'].duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all duplicate rows in a dataframe. Not an inplace operation.\n",
    "df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing and Exporting Dataframes\n",
    "We won't usually build our own dataframes but grab data from CSV files or a Database, so we have to learn to import and export data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading from a CSV file\n",
    "diamonds = pd.read_csv(\"../data/diamonds.csv\")\n",
    "diamonds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing to CSV\n",
    "diamonds['Junaid_verdict'] = np.where(diamonds.cut == \"Ideal\", \"Me Likey!\", \"Meh\")\n",
    "diamonds.to_csv(\"../data/diamonds_edited.csv\", index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "96cff63d46835ee138d10fd39d21d7d26297495ac413b2cb20db842db91a06fd"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('muslamic_makers_intro_data')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
